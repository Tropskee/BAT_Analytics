{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4b04d67-4d24-46ff-880a-d832b29c8f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andyczeropski/opt/miniconda3/envs/bat/lib/python3.10/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data ingested -- Found 53343 Rows\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "# Make NumPy printouts easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "## Read CSV\n",
    "data_source = \"../data/vehicle_data/final_bat_auction_data.csv\"\n",
    "df = pd.read_csv(data_source)\n",
    "\n",
    "print(f'Data ingested -- Found {len(df)} Rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f6b520d-8e6d-4abc-b4b8-95a49f17335f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique Makes: 74\n",
      "\n",
      "After:\n",
      " make               0\n",
      "model              0\n",
      "year               0\n",
      "miles              0\n",
      "final bid price    0\n",
      "color              0\n",
      "auction_year       0\n",
      "engine_size        0\n",
      "cylinders          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df.drop([\"Mileage Notes\", \"Details\"], inplace=True, axis=1)\n",
    "\n",
    "# rename columns to lowercase for easability\n",
    "df.columns = ['make', 'model', 'year', 'miles', 'final bid price', 'color',\n",
    "              'auction_year', 'engine_size', 'cylinders']\n",
    "\n",
    "# Drop any leftover nans\n",
    "df = df.dropna()\n",
    "print(\"Number of unique Makes:\", df.make.nunique())\n",
    "\n",
    "# Check nan values again\n",
    "print('\\nAfter:\\n', df.isna().sum())\n",
    "\n",
    "# name value to predict\n",
    "target_feature = \"final bid price\"\n",
    "\n",
    "y = df[target_feature]\n",
    "X = df.drop(target_feature, axis=1)\n",
    "# X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a86420bc-bc47-4524-b04c-0ca7df7d98b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating Numerical and Categorical Features...\n",
      "There are 8 total columns.\n",
      "There are 5 numerical features.\n",
      "There are 3 categorical features. \n",
      "\n",
      "Index(['make', 'model', 'year', 'miles', 'color', 'auction_year',\n",
      "       'engine_size', 'cylinders'],\n",
      "      dtype='object')\n",
      "Fetching Preprocessing Pipeline...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Find Numerical & Categorical Columns\n",
    "# Get numerical and categorical feature columns\n",
    "print('\\nCalculating Numerical and Categorical Features...')\n",
    "print(f'There are {len(X.columns)} total columns.')\n",
    "\n",
    "numerical_features = X.select_dtypes(include='number').columns.tolist()\n",
    "print(f'There are {len(numerical_features)} numerical features.')\n",
    "\n",
    "categorical_features = X.select_dtypes(exclude='number').columns.tolist()\n",
    "print(f'There are {len(categorical_features)} categorical features.', '\\n')\n",
    "\n",
    "print(X.columns)\n",
    "\n",
    "## Pre-Process Data\n",
    "\n",
    "print('Fetching Preprocessing Pipeline...\\n')\n",
    "\n",
    "numeric_pipeline = Pipeline(steps=[\n",
    "    ('impute', SimpleImputer(strategy='mean', missing_values=np.nan)),\n",
    "    ('scale', MinMaxScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('impute', SimpleImputer(strategy='most_frequent', missing_values=np.nan)),\n",
    "    ('one-hot', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "])\n",
    "\n",
    "full_processor = ColumnTransformer(transformers=[\n",
    "    ('number', numeric_pipeline, numerical_features),\n",
    "    ('category', categorical_pipeline, categorical_features)\n",
    "])\n",
    "\n",
    "\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "model = XGBRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "model_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', full_processor),\n",
    "        ('model', model)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fe6d6cc-b7bc-4f9d-b269-28708efd1061",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor(random_state=42, learning_rate=0.5, n_estimators=400, max_depth=5)\n",
    "\n",
    "\n",
    "model_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', full_processor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "hist = model_pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d4f96c0-39cd-4e9e-baa4-58e1d35fe5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([38067.54], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Custom Predictions\n",
    "tst_data = [\"subaru\", \"wrx sti\", 2016, 55000, \"blue\", 2022, 2.5, 4]\n",
    "columns = ['make', 'model', \"year\", 'miles', 'color', 'auction_year', 'engine_size', 'cylinders']\n",
    "tst = pd.DataFrame()\n",
    "for idx, col in enumerate(columns):\n",
    "    tst[col] = pd.Series(tst_data[idx])\n",
    "preds = model_pipeline.predict(tst)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7b076eb9-7531-4344-b44f-291df3f45061",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'XGBRegressor' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [31], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m r2\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# MSE = (1 - r2) * np.var(y)\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mhist\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meval\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'XGBRegressor' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "# .MSE(X, y)\n",
    "r2 = hist.score(X, y)\n",
    "r2\n",
    "\n",
    "# MSE = (1 - r2) * np.var(y)\n",
    "hist['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bda6c78-7671-4de2-a8a3-9411d5bb6f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../api/models/preprocessor.joblib']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the XGB model first:\n",
    "model_pipeline.named_steps['model'].save_model('../api/models/xgb_model.h5')\n",
    "\n",
    "# Save the preprocessor next\n",
    "joblib.dump(model_pipeline.named_steps['preprocessor'], '../api/models/preprocessor.joblib')\n",
    "\n",
    "\n",
    "# # This hack allows us to save the sklearn pipeline:\n",
    "# model_pipeline.named_steps['model'] = None\n",
    "\n",
    "# # Finally, save the pipeline:\n",
    "# joblib.dump(model_pipeline, './models/sklearn_pipeline.joblib')\n",
    "\n",
    "# del model_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87c3061-fcd2-473a-9c6c-6f96248dfb97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bat",
   "language": "python",
   "name": "bat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
